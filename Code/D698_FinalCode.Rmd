---
title: "D698 Final Project"
author: "Coffy Andrews-Guo, Vyanna Hill"
date: "`r Sys.Date()`"
output:
  prettydoc::html_pretty:
    theme: cayman
    highlight: github
vignette: >
  %\VignetteIndexEntry{Vignette Title}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r}
library(tidyverse)
library(ggpubr)
library(caret)
library(pROC) 
library(caTools)
library(h2o)
### Data Exploration
cali_data<-read_csv("C:/Users/walki/Documents/GitHub/D698/nri_cali.csv")

#Removing non important columns
#Note: WFIR_RISKS AND WFIR_RISV holds actual percentages of the likelihood, cannot be included as predictor value 
c_data<-cali_data%>%select(-c("...1","WFIR_RISKV","WFIR_RISKS","WFIR_HLRB"))

#Looking at the summary of all variables in the data set
summary(c_data)

#checking for null values
colSums(is.na(c_data))

#Reviewing the current distribution of the predictor values. See if there's future transformations
g1<-c_data%>%ggplot(aes(x=POPULATION))+geom_histogram(bins=20)+theme_light()
g2<-c_data%>%ggplot(aes(x=AREA))+geom_histogram(bins=20)+theme_light()
g3<-c_data%>%ggplot(aes(x=DRGT_EVNTS))+geom_histogram(bins=20)+theme_light()
g4<-c_data%>%ggplot(aes(x=DRGT_AFREQ))+geom_histogram(bins=20)+theme_light()
g5<-c_data%>%ggplot(aes(x=DRGT_HLRA))+geom_histogram(bins=20)+theme_light()
g6<-c_data%>%ggplot(aes(x=HWAV_EVNTS))+geom_histogram(bins=30)+theme_light()
g7<-c_data%>%ggplot(aes(x=HWAV_AFREQ))+geom_histogram(bins=20)+theme_light()
g8<-c_data%>%ggplot(aes(x=HWAV_HLRA))+geom_histogram(bins=20)+theme_light()
g9<-c_data%>%ggplot(aes(x=LTNG_EVNTS))+geom_histogram(bins=20)+theme_light()
g10<-c_data%>%ggplot(aes(x=LTNG_AFREQ))+geom_histogram(bins=20)+theme_light()
g11<-c_data%>%ggplot(aes(x=SWND_EVNTS))+geom_histogram(bins=20)+theme_light()
g12<-c_data%>%ggplot(aes(x=SWND_AFREQ))+geom_histogram(bins=30)+theme_light()
g13<-c_data%>%ggplot(aes(x=SWND_HLRA))+geom_histogram(bins=20)+theme_light()
g14<-c_data%>%ggplot(aes(x=WFIR_AFREQ))+geom_histogram(bins=20)+theme_light()
g15<-c_data%>%ggplot(aes(x=WFIR_EXPA))+geom_histogram(bins=20)+theme_light()
g16<-c_data%>%ggplot(aes(x=WFIR_EXPT))+geom_histogram(bins=20)+theme_light()
g17<-c_data%>%ggplot(aes(x=WFIR_EXP_AREA))+geom_histogram(bins=20)+theme_light()
g18<-c_data%>%ggplot(aes(x=WFIR_HLRP))+geom_histogram(bins=30)+theme_light()
g19<-c_data%>%ggplot(aes(x=WFIR_HLRA))+geom_histogram(bins=20)+theme_light()
g20<-c_data%>%ggplot(aes(x=WFIR_EALT))+geom_histogram(bins=20)+theme_light()
g21<-c_data%>%ggplot(aes(x=WFIR_EALS))+geom_histogram(bins=20)+theme_light()
g22<-c_data%>%ggplot(aes(x=WFIR_ALRA))+geom_histogram(bins=20)+theme_light()
g23<-c_data%>%ggplot(aes(x=TRCT_WAREA))+geom_histogram(bins=20)+theme_light()
g24<-c_data%>%ggplot(aes(x=TRCT_SLOPE))+geom_histogram(bins=30)+theme_light()
g25<-c_data%>%ggplot(aes(x=CNTY_ELEV))+geom_histogram(bins=20)+theme_light()
g26<-c_data%>%ggplot(aes(x=CNTY_TEMP))+geom_histogram(bins=20)+theme_light()
g27<-c_data%>%ggplot(aes(x=CNTY_PRECIP))+geom_histogram(bins=20)+theme_light()

#Plot for project write up, only a selected few
plt1<-ggarrange(g1,g2,g3,g4,g14,g22,g10,g7,nrow =4,ncol =2,align="h",heights = 2,font.label = list(size =3, color = "black"))

annotate_figure(plt1,top = text_grob("Distribution of Selected WildFire Predictor variables ",size=9))

#From distribution plots, wildfire values is most skewed. may need additional support in transformations

#Reviewing a few variables on its boxplots in reflection with the response variable WFRI_R
g1<-c_data%>%ggplot(aes(y=TRCT_SLOPE,x=factor(WFRI_R)))+geom_boxplot()+theme_light()+labs(x="WildFire Present",y="Tract Slope")
g2<-c_data%>%ggplot(aes(y=WFIR_HLRA,x=factor(WFRI_R)))+geom_boxplot()+theme_light()+labs(x="WildFire Present",y="WildFire Histortic Argiculture Loss Ratio")
g3<-c_data%>%ggplot(aes(y=CNTY_PRECIP,x=factor(WFRI_R)))+geom_boxplot()+theme_light()+labs(x="WildFire Present",y="Annual County Precipitation")
g4<-c_data%>%ggplot(aes(y=LTNG_EVNTS,x=factor(WFRI_R)))+geom_boxplot()+theme_light()+labs(x="WildFire Present",y="Annual Lighting Events")

plt1<-ggarrange(g1,g2,g3,g4,nrow =2,ncol =2,align="h",heights = 2,font.label = list(size =3, color = "black"))

annotate_figure(plt1,top = text_grob("Difference in Summary Statistics With Wildfire presence",size=9))


```

```{r}
### Data Preparation 

#transforming the tract vegetation life into binary dummy variables via mutate
unique(c_data$TRCT_VEGLF)
c_data<-c_data%>%mutate(.isShrub=if_else(TRCT_VEGLF=="Shrub",1,0),
                        .isTree=if_else(TRCT_VEGLF=="Tree",1,0),
                        .isDeveloped=if_else(TRCT_VEGLF=="Developed",1,0),
                        .isHerb=if_else(TRCT_VEGLF=="Herb",1,0),
                        .isArgiculture=if_else(TRCT_VEGLF=="Argiculture",1,0),
                        .isSparse=if_else(TRCT_VEGLF=="Sparse",1,0),
                        .isBarren=if_else(TRCT_VEGLF=="Barren",1,0),
                        .isSnowIce=if_else(TRCT_VEGLF=="Snow-Ice",1,0),
                        )
c_data<-c_data%>%select(-c("TRCT_VEGLF"))


#Seeing if there's multi-collinearity in the current predictors
#Drought events and drought frequency are highly correlated, Let's see with variable selection if one of the variables is dropped from the optimized predictor set
temp<-c_data%>%select(-c("WFRI_R","TRACTFIPS"))
temp<-cor(temp)

#setting the binary response and a few predictor variables as a factor before modeling
c_data<-c_data%>%mutate_at(c('WFRI_R',".isShrub",".isTree",".isDeveloped",".isHerb",".isArgiculture",".isSparse",".isBarren",".isSnowIce"),as.factor)

#splitting data set into testing and training
temp<-sample.split(c_data$WFRI_R,SplitRatio = 0.8)
training_data<-subset(c_data,temp==TRUE)
test_data<-subset(c_data,temp==FALSE)

```

```{r}
### Model Exploration

#Using H2o package for all models tested as the package offers multiple models and other features for validation
#connection to h20 server
h2o.init()

#Uploading the data set into h2o and splitting the dataset into training/test. Choosing an 80/20 split
train.h2o<-as.h2o(training_data)
test.h2o<-as.h2o(test_data)

#Model 1 Random Forest
#random forest- (like a decision tree, a collection of DTs with random subsets of the training set)
#suspect RF has better scores with sensitivity with the randomly selected features from each tree subset

#As RF will handle feature selection with its random subset. Removing drg_events to prevent multi-collinearity in the model
features<-c("POPULATION","AREA","DRGT_AFREQ","DRGT_HLRA","HWAV_EVNTS","HWAV_AFREQ","HWAV_HLRA","LTNG_EVNTS","LTNG_AFREQ","SWND_EVNTS","SWND_AFREQ","SWND_HLRA","WFIR_AFREQ","WFIR_EXPA","WFIR_EXPT","WFIR_EXP_AREA","WFIR_HLRP","WFIR_HLRA","WFIR_EALT","WFIR_EALS","WFIR_ALRA","TRCT_WAREA","TRCT_SLOPE","CNTY_ELEV","CNTY_TEMP","CNTY_PRECIP",".isShrub",".isTree",".isDeveloped",".isHerb",".isSparse",".isBarren",".isSnowIce")
response<-c("WFRI_R")

#creating RF model from the training set, setting up rf to have K cross-validation of 10
#Also included a stopping metric to be AUC measurement, It will cut to the most optimal level of trees based on the AUC score. Set ntrees at >300 to give as many trees before its cut-off
rf.model<-h2o.randomForest(x=features,y=response,training_frame = train.h2o,nfolds=10,stopping_metric = "AUC",ntrees=333,seed=333)

#retrieve current model statistics from the training set
rf.tresults<-rf.model@model$cross_validation_metrics_summary%>%select(c("mean","sd"))%>%t()

#using the rf model, see the performance on the test data set
#Accuracy 99%, R^2=97%, MSE=0.003
rf.score<-h2o.performance(rf.model,test.h2o)

#Printing out results from the first model and storing ROC Curve
rf.score
rf.roc<-rf.score@metrics$thresholds_and_metric_scores
rf.roc<-rf.roc%>%select(tpr,fpr)%>%ggplot(aes(x=fpr,y=tpr))+geom_point(color="black",size=0.5)+geom_segment(aes(x=0,y=0,xend=1,yend=1),linetype="dotted",color="red")+labs(x="Specificty",y="sensitivity",title = "Random Forest ROC Curve")+theme_light()

#review the feature importance of this random forest model
rf.features<-h2o.varimp(rf.model)
  
#Model 2 Ada Boosted Decision Tree Model
```

```{r}
### Data Analysis


#remembering all models are predictions of a logistic regression
#measurement of accuracy is different. Using McFadden's R^2 for measurement of fit and cross validation-Fit measurement, Error- AUC Curve
#We care about TP identifying correctly- Heavy on precision, Classification error, Accuracy
#second class- sensitivity, Specificity 


```
